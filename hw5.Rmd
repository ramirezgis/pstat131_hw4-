---
title: "hw5"
output: html_document
date: "2022-11-17"
---

Set up 
```{r}
library(tidymodels)
library(tidyverse)
library(dplyr)
#library(corrr)
library(ggplot2)
library(discrim)
library(klaR)
library(glmnet)
tidymodels_prefer()
pokemon <- read.csv("data/Pokemon.csv")
set.seed(1234)
head(pokemon)
```

Question 1
```{r}
library(janitor)
pokemon <- pokemon %>%
  clean_names() #names lowercase without periods/commas
#now underscore
```

With clean_names(), we see that the variables how are all lowercase and don't have periods or commas anymore and are replaced with underscore. This is useful so that the variables have a consistent variable format. 

Question 2
```{r}
barchart <- ggplot(data = pokemon, aes(x = type_1)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
barchart

#filter out rarer classes
pokemon_filter <- pokemon %>%
  filter(type_1 == c("Bug", "Fire", "Grass", "Normal", "Water", "Psychic"))
pokemon_factor <- pokemon_filter %>%
  mutate(type_1 = factor(type_1), 
         legendary = factor(legendary),
         generation = factor(generation))
```

There are 18 classes of type_1. There are a few Pokemon that are Flying and Fairy. There are also around 35 or less Pokemon that are Dark, Dragon, Fighting, Ghost, Ground, Ice, Poison, and Steel. 

Exercise 3
```{r}
pokemon_split <- initial_split(pokemon_factor, 
                               prop = 0.80, 
                               strata = type_1)
pokemon_split

pokemon_train <- training(pokemon_split)
pokemon_test <- testing(pokemon_split)

pokemon_folds <- vfold_cv(pokemon_train, v = 5, 
                          strata = type_1)
pokemon_folds

```

Stratifying the folds might be useful as we could divide also by the type of Pokemon to analyze. 

Exercise 4
```{r}
pokemon_recipe <-
  recipe(type_1 ~ legendary + generation + sp_atk + attack + speed + defense + 
           hp + sp_def, data = pokemon_train) %>%
  step_dummy(c("legendary", "generation")) %>% #all_nominal_predictors?
  step_center(all_predictors()) %>%
  step_scale(all_predictors())
pokemon_recipe
```


Exercise 5 
```{r}
multi_model <- multinom_reg(mixture = tune(), penalty = tune()) %>%
  set_engine("glmnet") %>%
  set_mode("classification")
multi_model


multi_wrkflow <- workflow() %>%
  add_model(multi_model) %>%
  add_recipe(pokemon_recipe)

pokemon_grid <- grid_regular(penalty(range = c(-5, 5)), 
                             mixture(range = c(0, 1)), levels = 10)
pokemon_grid
```

I'll be fitting 100 models.

Exercise 6
```{r}
#use autoplot()
tune_res <- tune_grid(
  multi_wrkflow,
  resamples = pokemon_folds, 
  grid = pokemon_grid
)
autoplot(tune_res)
```

I notice that a lot a lot of proportions of lasso penalty go down once it approaches 1e+00 amount of regularization. Smaller values of penalty and mixture produce better accuracy and ROC AUC. 

Exercise 7
```{r}
best_penalty <- select_best(tune_res, metric = "roc_auc") #rsq??
best_penalty

ridge_final <- finalize_workflow(multi_wrkflow, best_penalty)

ridge_final_fit <- fit(ridge_final, data = pokemon_train)

roc_auc1 <- augment(ridge_final_fit, new_data = pokemon_test) %>%
  select(type_1, starts_with(".pred")) 
roc_auc1#rsq??? #not roc_auc or multi_metric
```


Exercise 8 
```{r}
fit_1 <- roc_auc1 %>%
  roc_auc(type_1, .pred_Bug:.pred_Water)
fit_1 #0.744

fit_2 <- roc_auc1 %>%
  roc_curve(type_1, .pred_Bug:.pred_Water)
ggplot2::autoplot(fit_2)
#roc_curve

fit_3 <- augment(ridge_final_fit, new_data = pokemon_test) %>%
  conf_mat(truth = type_1, estimate = .pred_class)

autoplot(fit_3, type = "heatmap")
```

I notice that Grass has a really high ROC curve, which is the best at predicting. Also, Normal, Psychic and Water also have a semi high ROC curve and are also best are predicting but not as high as Grass types. Fire and Bug aren't that good at predicting and don't have as high ROC curve. This may be due to not having as much values (observations) as Grass, Normal, Psychic and Water which causes Fire and Bug to not have as high ROC curves. 
